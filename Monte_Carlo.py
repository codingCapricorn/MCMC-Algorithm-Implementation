# -*- coding: utf-8 -*-
"""Monte_Carlo.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1dNvJWH_B0dpcSeOJ7yfhU_unIJrw0Wvv

#Monte Carlo Method ::::

The concept was invented by Stanislaw Ulam, a mathematician who devised these methods as part of his contribution to the Manhattan Project. He used the tools of random sampling and inferential statistics to model likelihoods of outcomes, originally applied to a card game (Monte Carlo Solitaire). Ulam later worked with collaborator John von Neumann, using newly developed computer technologies to run simulations to better understand the risks associated with the nuclear project.

Monte Carlo (MC) methods are a subset of computational algorithms that use the process of repeated random sampling to make numerical estimations of unknown parameters. They allow for the modeling of complex situations where many random variables are involved, and assessing the impact of risk. The uses of MC are incredibly wide-ranging, and have led to a number of groundbreaking discoveries in the fields of physics, game theory, and finance. 

There are three main reasons to use Monte Carlo methods to randomly sample a probability distribution; they are:

(1)Estimate density:gather samples to approximate the distribution of a target function.

(2)Approximate a quantity:such as the mean or variance of a distribution.

(3)Optimize a function:locate a sample that maximizes or minimizes the target function.

#Monte Carlo Method For Sampling probability distribution ::::

In this case, we will have a function that defines the probability distribution of a random variable. We will use a Gaussian distribution with a mean of 50 and a standard deviation of 5 and draw random samples from this distribution.We can draw a sample of a given size and plot a histogram to estimate the density.

The normal() NumPy function can be used to randomly draw samples from a Gaussian distribution with the specified mean (mu), standard deviation (sigma), and sample size.

We will repeat this experiment four times with different sized samples. We would expect that as the size of the sample is increased, the probability density will better approximate the true density of the target function, given the law of large numbers.
"""

# example of effect of size on monte carlo sample
from numpy.random import normal
from matplotlib import pyplot
# define the distribution
mu = 50
sigma = 5
# generate monte carlo samples of differing size
sizes = [10, 50, 100, 1000]
for i in range(len(sizes)):
	# generate sample
	sample = normal(mu, sigma, sizes[i])
	# plot histogram of sample
	pyplot.subplot(2, 2, i+1)
	pyplot.hist(sample, bins=20)
	pyplot.title('%d samples' % sizes[i])
	pyplot.xticks([])
# show the plot
pyplot.show()

"""##“As the number of identically distributed, randomly generated variables increases, their sample mean (average) approaches their theoretical mean.”

#Monte Carlo Integration For Finding Value Of PI ::::

We can implement $\pi$ estimator as follows ::

For every single value of 10,100,1000,10000 and finally at 100000 ,1000000 .....

The more accurate value of $\pi$ can be stimated.......
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import matplotlib.pyplot as plt
# %matplotlib inline
#Defining the lines of the square:
horiz = np.array(range(100))/100.0
y_1 = np.ones(100)
plt.plot(horiz , y_1, 'b')
vert = np.array(range(100))/100.0
x_1 = np.ones(100)
plt.plot(x_1 , vert, 'b')
#Plotting the random points:
import random
inside = 0
i=1
n=int(input("Enter the total number of points: "))
while (i<=n):
  x = random.random()
  y = random.random()
  if ((x**2)+(y**2))<=1:
    inside+=1
    plt.plot(x , y , 'go')
  else:
    plt.plot(x , y , 'ro')
  i+=1
pi=(4*inside)/n
print ("The value of pi is:")
print(pi)
plt.show()
plt.savefig("Piii")

import numpy as np
import matplotlib.pyplot as plt
n = 1000000
x = np.random.rand(n,2)
inside =x[np.sqrt(x[:,0]**2+x[:,1]**2) < 1]
estimate = 4*len(inside)/len(x)
print("Estimate of pi: {}".format(estimate)) 
plt. figure(figsize=(8,8)) 
plt.scatter(x[:,0], x[:,1],s= 0.5, c='red')
plt.scatter(inside[:,0], inside[ :,1], s=0.5 ,c='blue')
plt.show()

